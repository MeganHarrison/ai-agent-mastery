# Determines how environment variables are loaded
# Set this to either production or development
ENVIRONMENT=

# Base URL for the OpenAI compatible instance that has embedding models (default is https://api.openai.com/v1)
# OpenAI: https://api.openai.com/v1
# Ollama (example): http://localhost:11434/v1
EMBEDDING_BASE_URL=

# OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# Ollama: Just set this to a placeholder like ollama unless you specifically configured an API key
EMBEDDING_API_KEY=

# The embedding model you want to use for RAG.
# Make sure the embeddings column in your database has the same dimensions as this embedding model!
# OpenAI example: text-embedding-3-small
# Ollama example: nomic-embed-text
EMBEDDING_MODEL_CHOICE=

# Supabase configuration
# Get these from your Supabase project settings -> API
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# For the Local AI Package:
#   The Supabase URL is http://kong:8000 (when running in Docker) or http://localhost:8000 (pipeline is outside of Docker)
#   The Service Key you get from your package .env
SUPABASE_URL=
SUPABASE_SERVICE_KEY=
